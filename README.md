<h1 align="center">
  <img src="Logo_Maif_2019.svg.png" alt="MAIF" style="height: 200px;">
  <br />
</h1>

<p align="center">Prototype dâ€™outil <b>local</b> dâ€™analyse de conversations tÃ©lÃ©phoniques pour la MAIF, dÃ©veloppÃ© dans le cadre du <b>use case MAIF â€“ AI4Industry</b>.
</p>

<p align="center"><i>"VocalisAI"</i></p>

---

Lâ€™application permet :

* le **prÃ©traitement audio** (VAD),
* la **transcription avec diarisation**,
* la **synthÃ¨se structurÃ©e** des appels,
* via une **interface web Flask**.

---

## PrÃ©requis

* **Python 3.12+** (voir `.python-version` / `pyproject.toml`)
* **pip** ou **uv**
* **GPU recommandÃ©** (CUDA ou Apple Silicon MPS) pour WhisperX et les modÃ¨les LLM
* **Hugging Face token** (pour PyAnnote / diarisation WhisperX)

---

## Installation

### 1. Environnement virtuel

```bash
python -m venv .venv
source .venv/bin/activate
```

### 2. Installation des dÃ©pendances

Avec **pip** :

```bash
pip install -r requirements.txt
```

Avec **uv (recommandÃ©)** :

```bash
uv sync
```

---

## Lancement de lâ€™application

Dans un terminal Ã  part, lancez Ollama:

```bash
ollama serve
```

Depuis la racine du projet :

```bash
uv run flask --app web/main.py run
```

Lâ€™interface est accessible sur :
ðŸ‘‰ **[http://127.0.0.1:5000](http://127.0.0.1:5000)**

---

## Utilisation

1. AccÃ©der Ã  lâ€™interface web
2. Charger un fichier audio (WAV, MP3, FLAC, etc.)
3. Lancer lâ€™analyse
4. Les rÃ©sultats affichÃ©s incluent :

   * transcription avec diarisation
   * rÃ©sumÃ© structurÃ© MAIF
   * mÃ©tadonnÃ©es audio

---

## Structure du projet (rÃ©elle)

```
USECASEMAIF/
â”œâ”€â”€ .venv/                     # Environnement virtuel (local)
â”œâ”€â”€ code_tests/                # Scripts et tests exploratoires
â”‚
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                # Point dâ€™entrÃ©e Flask
â”‚   â”œâ”€â”€ processor.py           # Pipeline principal (audio â†’ texte â†’ rÃ©sumÃ©)
â”‚   â”œâ”€â”€ preprocessing.py       # PrÃ©traitement audio (VAD rVADfast)
â”‚   â”œâ”€â”€ summarize.py           # SynthÃ¨se structurÃ©e via LLM
â”‚   â”œâ”€â”€ patch_lightning.py     # Monkey-patch PyTorch / Lightning (compatibilitÃ© WhisperX)
â”‚   â”‚
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html         # Interface utilisateur
â”‚   â”‚
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ script.js          # Logique frontend (upload, requÃªtes)
â”‚       â””â”€â”€ style.css          # Styles CSS
â”‚
â”œâ”€â”€ .env                       # Variables dâ€™environnement (HF_TOKEN, etc.)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .python-version
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ uv.lock
â””â”€â”€ README.md
```

---

## Description des modules clÃ©s

### `web/main.py`

* Initialise le serveur **Flask**
* GÃ¨re les routes HTTP
* Orchestration globale du pipeline

### `web/preprocessing.py`

* PrÃ©traitement audio
* **Voice Activity Detection (rVADfast)**
* Normalisation, mono, resampling 16 kHz
* Fallback sÃ©curisÃ© si aucun speech dÃ©tectÃ©

### `web/processor.py`

* Pipeline principal :

  * appel du prÃ©traitement
  * transcription WhisperX
  * gestion diarisation
  * collecte des rÃ©sultats
* Extraction des mÃ©tadonnÃ©es audio

### `web/summarize.py`

* GÃ©nÃ©ration de **rÃ©sumÃ©s structurÃ©s MAIF**
* Utilise `transformers` + modÃ¨le LLM local
* Format strict (problÃ©matique, rÃ©sumÃ©, actions, etc.)

### `web/patch_lightning.py`

* Monkey-patch de `lightning_fabric.utilities.cloud_io`
* Contournement du problÃ¨me `torch.load(weights_only=True)`
* NÃ©cessaire avec certaines versions de PyTorch / WhisperX

---

## Technologies utilisÃ©es

### Interface Web

* **Flask**
* HTML / CSS / JavaScript

### Audio & Transcription

* **WhisperX** : transcription + diarisation
* **PyTorch**
* **PyAnnote** (via WhisperX)
* **rVADfast** : Voice Activity Detection
* **audiofile**, **librosa**, **numpy**

### RÃ©sumÃ© & NLP

* **transformers**
* **AutoModelForCausalLM**
* ModÃ¨les LLM locaux (GPU / MPS)

### Configuration

* **python-dotenv**
* **Pydantic**
* Variables dâ€™environnement via `.env`

---

## Configuration importante

CrÃ©er un fichier `.env` Ã  la racine :

```env
HF_TOKEN=hf_xxxxxxxxxxxxxxxxx
```

---

## Notes importantes

* Les modÃ¨les sont tÃ©lÃ©chargÃ©s **au premier lancement**
* La diarisation nÃ©cessite un **token Hugging Face**
* Le traitement peut Ãªtre long sur CPU
* Projet **prototype / expÃ©rimental**, non destinÃ© Ã  la production

---

## Statut du projet

* âœ” Pipeline fonctionnel
* âœ” Interface web opÃ©rationnelle
* âœ” PrÃ©traitement audio robuste
* âš  Optimisations GPU / perfs en cours
* âš  Gestion des erreurs WhisperX dÃ©pendante des versions PyTorch
